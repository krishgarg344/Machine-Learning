# -*- coding: utf-8 -*-
"""3014_Lab4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13jEniAKMAUdkcqkVEKgf7qOr9pDIKuz0
"""

# Importing packages
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier

# dataset of a bank marketing campaign
df = pd.read_csv('bank.csv')

df.head()

df.info()

df.isnull().sum()

df.isnull().sum().sum()

cols = [col for col in df.columns if df[col].dtype == 'object']
for col in cols:
  print(df[col].value_counts())

df.drop(columns = ['job', 'month'], inplace = True)

df = pd.get_dummies(df, columns = ['marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome'], drop_first = True)

df.info()

df.head()

# doing EDA omn columns to see for relevance of features w.r.t. output feature 'deposit'
for col in df.columns:
  if col != 'deposit':
    plt.figure(figsize = (10, 5))
    print(f"Plot for feature {col}")
    sns.histplot(data = df, x = col, hue = 'deposit',  multiple="stack", kde=True)
    plt.title(f"plot of {col} vs deposit column")
    plt.tight_layout
    plt.show()

y = df['deposit']
X = df.drop(columns = ['deposit'])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)

from sklearn.model_selection import cross_val_score

# range of k
k_range = range(1, 26)
cv_scores = []
for k in k_range:
    knn = KNeighborsClassifier(n_neighbors=k)
    scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='accuracy')
    cv_scores.append(scores.mean())

# plotting accuracy vs k
plt.figure(figsize=(8, 5))
plt.plot(k_range, cv_scores, marker='o')
plt.title("k-NN Cross-Validation Accuracy vs k")
plt.xlabel("Number of Neighbors: k")
plt.ylabel("Cross-Validated Accuracy")
plt.grid(True)
plt.show()

# printing best k
best_k = k_range[np.argmax(cv_scores)]
print(f"Best k from cross-validation: {best_k}")

from sklearn.metrics import accuracy_score
knn = KNeighborsClassifier(n_neighbors=21)
knn.fit(X_train, y_train)
# Predict and evaluate
y_pred = knn.predict(X_test)
print(f"Test Accuracy (k=21): {accuracy_score(y_test, y_pred):.2f}")

K=[]
training=[]
test=[]
scores={}
for k in range(2,21):
    clf=KNeighborsClassifier(n_neighbors=k)
    clf.fit(X_train,y_train)
    training_score=clf.score(X_train,y_train)
    test_score=clf.score(X_test,y_test)
    K.append(k)
    training.append(training_score)
    test.append(test_score)
    scores[k]=[training_score,test_score]

for keys,values in scores.items():
    print(keys,":",values)

plt.scatter(K,training)
plt.xlabel('values  of K')
plt.ylabel('Training Score')
plt.show()

plt.scatter(K,test)
plt.xlabel('values  of K')
plt.ylabel('Training Score')
plt.show()

plt.scatter(K,training)

plt.scatter(K,test)
plt.legend(['testing'])
plt.savefig('a2.png')
plt.show()

clf=KNeighborsClassifier(n_neighbors=5)
clf.fit(X_train,y_train)
y_pred=clf.predict(X_test)
training_score=clf.score(X_train,y_train)
test_score=clf.score(X_test,y_test)

print(training_score,test_score)

from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

print(accuracy_score(y_test,y_pred))

print(classification_report(y_test,y_pred))

sale_data = pd.DataFrame({
    'OrderID' : [102, 45, 76, 34, 90],
    'Product' : ['Laptop', 'Mouse', 'WebCam', 'Keyboard', 'Mousepad'],
    'Price' : [50000, 1000, 2000, 1500, 800],
    'Quantity' : [10, 44, 70, 60, 200],
    'CustomerID': [201, 202, 201, 203, 202],
    'Discount': [0.10, 0.0, 0.15, 0.05, 0.0]
})

last_year_data = pd.DataFrame({
    'OrderID' : [100, 49, 69, 34, 8],
    'Product' : ['Laptop', 'Mouse', 'WebCam', 'Keyboard', 'Mousepad'],
    'Price' : [40000, 800, 1900, 1700, 400],
    'Quantity' : [5, 66, 56, 54, 100],
    'CustomerID': [101, 67, 787, 344, 113],
    'Discount': [0.20, 0.1, 0.45, 0.25, 0.1]
})

features = ['OrderID',  'Price', 'Quantity', 'CustomerID', 'Discount']

tree = KDTree(sale_data[features])
closest = []
for idx, row in last_year_data.iterrows():
    X = row[features].values.reshape(1, -1)
    distances, ndx = tree.query(X, k=2, return_distance=True)
    print(distances, ndx)
    closest.append(ndx)

    TheProduct = last_year_data.loc[idx, 'Product']
    LastProduct = [ sale_data.loc[x,'Product'] for x in ndx[0] ]

    print ('%s closest to: %s' %(sale_data, last_year_data))

sale_data[features].shape

sale_data[features]

